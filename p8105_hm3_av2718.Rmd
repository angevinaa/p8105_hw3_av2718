---
title: "p8105_hw3_av2718"
author: "Angelica Vina Albarracin"
date: "2022-10-15"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, message = FALSE)
```

```{r load_libraries}
library(tidyverse)   #load packages 
library(dplyr)
```

## Problem 2

This problem focuses on the Accelerometers data. Below we import and clean data from `accel_data.csv`. The process begins with importing the data and cleaning the variables names:

```{r}
library(readr)
accel_data = read_csv("data/accel_data.csv") %>% #import data
  janitor::clean_names() %>% # tidy variable names
  mutate_if(is.double, as.numeric) #if double mutate variable to   numeric
```

We quickly recognize a problem: the `activity` data is spread across 1443 columns, which correspond to 1443 activity counts for each minute of a 24-hour day. To address this and organize the data, we will use `pivot_longer`to wangle the activity data and create two new variables `workweek` and `weekday`:

```{r}
accel_data_tidy =  
  pivot_longer(   # organize activity data 
    accel_data,
    activity_1:activity_1440,
    names_to = "time_course",
    values_to = "activity_count",
    names_prefix = "activity_"                  
  ) %>%
  mutate(.data = .,  # new weekday vs weekend variable
         workweek = if_else(day %in% c("Saturday", "Sunday"), "weekend", "weekday"),
         weekday = fct_relevel(day, "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")) 

head(accel_data_tidy, 8) #view first 8 rows of tidied data
```

The resulting dataset has only 6 variables: `r ls(accel_data_tidy)`, and a size of `r dim(accel_data_tidy)`. Using this tidied dataset, we will now aggregate across minutes to create a `total_activity` variable for each day, and create a table showing these totals:

```{r}
total_activity = accel_data_tidy %>%  
  group_by(day,week) %>%           #Group total activity by day and week 
  summarize(day_total = sum(activity_count)) %>% 
  mutate(week = as.character(week))


pivot_wider(                 #Create friendly table for "human readers"
  total_activity,
  names_from = "day",
  values_from = "day_total"
)

```

As expected, from the table, we observe different total activity levels depending on the day of the week. The patient seems to be more active during the weekdays vs weekends. However, the data presented in this table isn't enough to make any conclusions. We would need to conduct further analysis. Nonetheless, from this table, we can observe on Saturday week 4 and Saturday week 5 two unusual measurements, possibly due to a device malfunction. It's good that we noticed this issue, as it will affect our analysis and results.

We will now use what we have learned in class to the inspection activity over the course of the day. In the code chuck below we will create a single-panel `plot` that shows the 24-hour activity time courses for each day and use color to indicate the day of the week:

```{r}
f1 = ggplot(accel_data_tidy, aes(x = time_course, y = activity_count, color = day)) +
  geom_line() +
  theme_minimal() +
  theme(legend.position = "bottom") +  # Legend in bottom
  theme(plot.title = element_text(hjust = 0.5)) + # Center plot title
  labs(
    title = "24-hour Accelerometer Activity Count for Each Week Day",  # add tittle  
    x = "Time Course (Minutes)",
    y = "Activity Count", # label x and y axis
  )

f1
```

Based on this graph, we can say that the patient's physical activity fluctuates across the day. In general, we observe peak activity early in the day and a decrease in activity count during the middle of the day. During the weekdays, the patient seems to be more active in the morning and less active at night. On Saturday and Sunday, we observe more physical activity both in the morning and at night. However, it's difficult to describe a specific pattern or make a definite conclusion based on this graph alone. It would be interesting to know the expected or recommended activity level for a 63-year-old to have a benchmark against which we can analyze the patient's daily activity level.

## Problem 3

```{r}
library(p8105.datasets)
library(dplyr)
library(rnoaa)
data("ny_noaa")
```

In this problem we will explore the `ny_noaa` data. We use a similar process as in Problem 1 to import, clean, and organize the data.

**Step 1:** We ensure observations for temperature, precipitation, and snowfall are given in reasonable units, and create separate variables for year, month, and day.

```{r}
ny_noaa_tidy = ny_noaa %>% 
  janitor::clean_names() %>% 
  mutate(  
    tmax = as.numeric(tmax),   #change tmax and tmin to numeric
    tmin = as.numeric(tmin),
    tmax = tmax/10,       #adjust temperature units to celsius
    tmin = tmin/10
  ) %>% 
  separate(date, into = c("year","month","day")) #separate date into year, month, and day

```

**Step 2:** We use the function `count` to get a sense of the distribution of `snow`:

```{r}
ny_noaa_tidy %>% 
  count(snow)
```

As expected, we can observe from the most commonly observed value of `snow` is O, which makes sense since in New York it doesn't snow most of the year.

**Step 3:** In the following code chunk, we make a two-panel plot showing the average max temperature in January and July. To create the plot, we first have filter our `ny_noaa_tidy` data to select the maximum temperature data for the months of January and July. We then calculate the mean temperature and create the plot.

```{r}
max_temp = filter(
  ny_noaa_tidy, month %in% c("01", "07")) %>% #Filter ny_noaa data by month
  mutate(
    month = recode(month, `01` = "January", `07` = "July") #Change month from number to letters
  ) %>% 
  select(.data = ., id, year, month, tmax) %>% #Select data 
  group_by(id, year, month) %>% #Group data by id, year, and moth
  summarize(tmax_mean = mean(tmax, na.rm = TRUE)) #Calculate average maximum temperature

ggplot(max_temp, aes(x = year, y = tmax_mean, group = id)) +  #create plot of average max temperature
  geom_line(aes(color = tmax_mean)) +
  scale_x_discrete(
    breaks = c(1980, 1985, 1990, 1995, 2000, 2005, 2010),
    labels = c("1980","1985", "1990","1995","2000","2005","2010")
  ) +
  theme_minimal() +
  # theme(legend.position = "bottom") +
  facet_grid(. ~ month) +  #Create separate panel for each month 
  labs(
    title = "Average Maximum Temperature in NYC Subway (1980-2010)", #add tittle  
    x = "Year",
    y = "Average Maximum Temperature (Celsius)") #label x and y axis
  theme(plot.title = element_text(hjust = 0.5))  #center plot title 
```



